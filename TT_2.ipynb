{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46534d0e",
   "metadata": {},
   "source": [
    "# Trabajo Terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacc0dc",
   "metadata": {},
   "source": [
    "### Análisis exploratorio de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b870ad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_10784\\2302935929.py:10: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  \"D:\\Intelingencia Artificial\\Semestre Final\\Trabajo Terminal II\\Primer departamental\\IndividuosS1-S7(17columnas)-Epocas.mat\", struct_as_record=False, squeeze_me=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'S'])\n",
      "Tipo de dato: <class 'numpy.ndarray'>\n",
      "Las dimensiones del dataset es: (7,): \n",
      "El numero de sujetos es: 7 \n",
      "Version del dataset: 1.0\n",
      "Encabezado columnas: b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Fri Feb 02 17:37:42 2018'\n",
      "Tipo de campo: <class 'scipy.io.matlab._mio5_params.mat_struct'>\n",
      "Estructura ['Palabra', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_fieldnames']\n",
      "Palabras tipo: <class 'numpy.ndarray'>\n",
      "Numero de palabras: (5,)\n",
      "Directorio palabras['Epoca', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_fieldnames']\n",
      "Tipo de dato de épocas: <class 'numpy.ndarray'>\n",
      "Directorio epocas['SenalesEEG', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_fieldnames']\n",
      "Numwero de épocas: (33,)\n",
      "Tipo de dato de canales: <class 'numpy.ndarray'>\n",
      "Directorio canales['T', '__abs__', '__add__', '__and__', '__array__', '__array_finalize__', '__array_function__', '__array_interface__', '__array_prepare__', '__array_priority__', '__array_struct__', '__array_ufunc__', '__array_wrap__', '__bool__', '__buffer__', '__class__', '__class_getitem__', '__complex__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dir__', '__divmod__', '__dlpack__', '__dlpack_device__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__ilshift__', '__imatmul__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__xor__', 'all', 'any', 'argmax', 'argmin', 'argpartition', 'argsort', 'astype', 'base', 'byteswap', 'choose', 'clip', 'compress', 'conj', 'conjugate', 'copy', 'ctypes', 'cumprod', 'cumsum', 'data', 'diagonal', 'dot', 'dtype', 'dump', 'dumps', 'fill', 'flags', 'flat', 'flatten', 'getfield', 'imag', 'item', 'itemset', 'itemsize', 'max', 'mean', 'min', 'nbytes', 'ndim', 'newbyteorder', 'nonzero', 'partition', 'prod', 'ptp', 'put', 'ravel', 'real', 'repeat', 'reshape', 'resize', 'round', 'searchsorted', 'setfield', 'setflags', 'shape', 'size', 'sort', 'squeeze', 'std', 'strides', 'sum', 'swapaxes', 'take', 'tobytes', 'tofile', 'tolist', 'tostring', 'trace', 'transpose', 'var', 'view']\n",
      "Numero de canales: (225, 17)\n",
      " COLUMNA Etiqueta            Tipo      Ubicación\n",
      "       1      AF3    Canal de EEG    Pre-frontal\n",
      "       2       F7    Canal de EEG        Frontal\n",
      "       3       F3    Canal de EEG        Frontal\n",
      "       4      FC5    Canal de EEG Fronto-central\n",
      "       5       T7    Canal de EEG       Temporal\n",
      "       6       P7    Canal de EEG       Parietal\n",
      "       7       O1    Canal de EEG      Occipital\n",
      "       8       O2    Canal de EEG      Occipital\n",
      "       9       P8    Canal de EEG       Parietal\n",
      "      10       T8    Canal de EEG       Temporal\n",
      "      11      FC6    Canal de EEG Fronto-central\n",
      "      12       F4    Canal de EEG        Frontal\n",
      "      13       F8    Canal de EEG        Frontal\n",
      "      14      AF4    Canal de EEG    Pre-frontal\n",
      "      15    GIROX Giroscopio en x              -\n",
      "      16    GIROY Giroscopio en y              -\n",
      "      17   MARKER        Marcador              -\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PyEMD import EMD\n",
    "\n",
    "data = loadmat(\n",
    "    \"D:\\Intelingencia Artificial\\Semestre Final\\Trabajo Terminal II\\Primer departamental\\IndividuosS1-S7(17columnas)-Epocas.mat\", struct_as_record=False, squeeze_me=True\n",
    ")\n",
    "####### Entender Estructura principal ##########\n",
    "print(data.keys())\n",
    "S = data['S']\n",
    "Numero_sujeto = S.shape[0]\n",
    "Longitud = S.shape\n",
    "Palabras = S[0].Palabra\n",
    "Epocas = S[0].Palabra[0].Epoca\n",
    "Canales = S[0].Palabra[0].Epoca[0].SenalesEEG\n",
    "print(\"Tipo de dato:\", type(S))\n",
    "print(f\"Las dimensiones del dataset es: {Longitud}: \")\n",
    "print(f\"El numero de sujetos es: {Numero_sujeto} \")\n",
    "print(\"Version del dataset:\", data['__version__'])\n",
    "print(\"Encabezado columnas:\", data['__header__'])\n",
    "print(\"Tipo de campo:\", type(S[0]))\n",
    "print(\"Estructura\", dir(S[0]))\n",
    "print(\"Palabras tipo:\", type(Palabras))\n",
    "print(\"Numero de palabras:\", Palabras.shape)\n",
    "print(f\"Directorio palabras{dir(Palabras[0])}\")\n",
    "print(\"Tipo de dato de épocas:\", type(Epocas))\n",
    "print(f\"Directorio epocas{dir(Epocas[0])}\")\n",
    "print(\"Numwero de épocas:\", np.shape(Epocas))\n",
    "print(\"Tipo de dato de canales:\", type(Canales))\n",
    "print(f\"Directorio canales{dir(Canales[0])}\")\n",
    "print(\"Numero de canales:\", np.shape(Canales))\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"COLUMNA\": list(range(1, 18)),\n",
    "    \"Etiqueta\": [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\",\n",
    "                 \"FC6\", \"F4\", \"F8\", \"AF4\", \"GIROX\", \"GIROY\", \"MARKER\"],\n",
    "    \"Tipo\": [\"Canal de EEG\"] * 14 + [\"Giroscopio en x\", \"Giroscopio en y\", \"Marcador\"],\n",
    "    \"Ubicación\": [\"Pre-frontal\", \"Frontal\", \"Frontal\", \"Fronto-central\", \"Temporal\",\n",
    "                  \"Parietal\", \"Occipital\", \"Occipital\", \"Parietal\", \"Temporal\",\n",
    "                  \"Fronto-central\", \"Frontal\", \"Frontal\", \"Pre-frontal\", \"-\", \"-\", \"-\"]\n",
    "}\n",
    "\n",
    "# Crear un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar tabla sin necesidad de tabulate\n",
    "print(df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba983b5f",
   "metadata": {},
   "source": [
    "### Conteo de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0f2d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indice: 1 -> Arriba\n",
      "indice: 2 -> Abajo\n",
      "indice: 3 -> Izquierda\n",
      "indice: 4 -> Derecha\n",
      "indice: 5 -> Seleccionar\n",
      "Sujeto 1:\n",
      "------------------------------\n",
      "Sujeto 2:\n",
      "------------------------------\n",
      "Sujeto 3:\n",
      "  Palabra 1: 34 épocas\n",
      "------------------------------\n",
      "Sujeto 4:\n",
      "------------------------------\n",
      "Sujeto 5:\n",
      "------------------------------\n",
      "Sujeto 6:\n",
      "------------------------------\n",
      "Sujeto 7:\n",
      "  Palabra 5: 32 épocas\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "etiquetas_palabras = {\n",
    "    0: \"Arriba\",\n",
    "    1: \"Abajo\",\n",
    "    2: \"Izquierda\",\n",
    "    3: \"Derecha\",\n",
    "    4: \"Seleccionar\"\n",
    "}\n",
    "\n",
    "for idx, nombre in etiquetas_palabras.items():\n",
    "    print(f\"indice: {idx+1} -> {nombre}\")\n",
    "for i in range(7):\n",
    "    sujeto = S[i]\n",
    "    print(f\"Sujeto {i + 1}:\")\n",
    "    for j, palabra in enumerate(sujeto.Palabra):\n",
    "        num_epocas = len(palabra.Epoca)\n",
    "        if num_epocas != 33:\n",
    "            print(f\"  Palabra {j+1}: {num_epocas} épocas\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed6dcb6",
   "metadata": {},
   "source": [
    "### Visualización de canales no ejecutar si no es necesario \"No ejecutes este beto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b41675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def guardar_epoca(S, suj, pal, ep, outdir=\"figs_todas_epocas\"):\n",
    "    \"\"\"suj, pal, ep son índices 1-based.\"\"\"\n",
    "    X = S[suj-1].Palabra[pal-1].Epoca[ep-1].SenalesEEG\n",
    "    eeg = X[:, :14]\n",
    "    t = np.arange(eeg.shape[0]) / FS\n",
    "    nombre_pal = etiquetas_palabras[pal-1]\n",
    "\n",
    "    pal_dir = os.path.join(outdir, f\"Sujeto_{suj}\", f\"Palabra_{nombre_pal}\")\n",
    "    os.makedirs(pal_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for ch in range(14):\n",
    "        plt.plot(t, eeg[:, ch], linewidth=1, label=CANAL_EEG[ch])\n",
    "    plt.title(f\"Sujeto {suj} | {nombre_pal} | Época {ep} | {eeg.shape[0]} muestras (~{eeg.shape[0]/FS:.2f}s)\")\n",
    "    plt.xlabel(\"Tiempo (s)\"); plt.ylabel(\"Amplitud (EEG)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(ncol=4, fontsize=8, loc=\"upper center\", bbox_to_anchor=(0.5, -0.15))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = f\"S{suj}_P{pal}_E{ep}_canales-superpuestos.png\"\n",
    "    plt.savefig(os.path.join(pal_dir, fname), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# === Recorre TODOS los sujetos, TODAS las palabras y TODAS las épocas ===\n",
    "OUTDIR = \"figs_todas_epocas\"\n",
    "for suj in range(1, len(S) + 1):\n",
    "    for pal in range(1, 6):  # 1..5\n",
    "        n_ep = len(S[suj-1].Palabra[pal-1].Epoca)\n",
    "        for ep in range(1, n_ep + 1):\n",
    "            guardar_epoca(S, suj, pal, ep, outdir=OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357f77c",
   "metadata": {},
   "source": [
    "### Descomposición en Modos Empiricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sujetos: 7\n"
     ]
    }
   ],
   "source": [
    "#-------------CONSTANTES--------------------Solo cambiar ruta--------------#\n",
    "mat_path = Path(r\"D:\\Intelingencia Artificial\\Semestre Final\\Trabajo Terminal II\\Primer departamental\\IndividuosS1-S7(17columnas)-Epocas.mat\")\n",
    "mat = loadmat(str(mat_path), struct_as_record=False, squeeze_me=True)\n",
    "S = mat['S']\n",
    "FS = 128\n",
    "CANAL_EEG = ['AF3','F7','F3','FC5','T7','P7','O1','O2','P8','T8','FC6','F4','F8','AF4']\n",
    "etiquetas_palabras = {0:\"Arriba\",1:\"Abajo\",2:\"Izquierda\",3:\"Derecha\",4:\"Seleccionar\"}\n",
    "print(\"Sujetos:\", S.shape[0])\n",
    "#----------------------------------------------------------------------------------#\n",
    "\n",
    "MAX_IMF = 5\n",
    "NORMALIZAR = True\n",
    "emd_obj = EMD()\n",
    "\n",
    "def preproc_1d(x):\n",
    "    \"\"\"NaNs -> interp, quitar DC, normalizar opcional.\"\"\"\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    if np.isnan(x).any():\n",
    "        n = len(x); t = np.arange(n)\n",
    "        mask = ~np.isnan(x)\n",
    "        x = np.interp(t, t[mask], x[mask])\n",
    "    x = x - np.mean(x)\n",
    "    if NORMALIZAR:\n",
    "        std = np.std(x)\n",
    "        if std > 0:\n",
    "            x = x / std\n",
    "    return x\n",
    "\n",
    "def compute_imfs_1d(x, max_imf=5):\n",
    "    \"\"\"Devuelve lista de IMFs (sin None).\"\"\"\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    if len(x) < 16:\n",
    "        return []\n",
    "    try:\n",
    "        imfs = emd_obj.emd(x)  # (sin cambios)\n",
    "    except Exception as e:\n",
    "        print(\"EMD falló:\", e)\n",
    "        return []\n",
    "\n",
    "    if imfs is None:\n",
    "        return []\n",
    "\n",
    "    imfs = np.asarray(imfs)\n",
    "    if imfs.ndim == 1:\n",
    "        imfs = imfs[np.newaxis, :]\n",
    "\n",
    "    if imfs.shape[0] == len(x) and imfs.shape[1] != len(x):\n",
    "        imfs = imfs.T\n",
    "\n",
    "    if imfs.shape[1] != len(x):\n",
    "        print(\"Aviso: forma inesperada de imfs devuelta por PyEMD:\", imfs.shape)\n",
    "        return []\n",
    "\n",
    "    n_keep = min(max_imf, imfs.shape[0])\n",
    "    out = [imfs[k, :].astype(float) for k in range(n_keep)]\n",
    "    return out\n",
    "\n",
    "def completar_imfs(imfs, max_imf=5):\n",
    "    imfs = list(imfs)\n",
    "    if len(imfs) == 0:\n",
    "        return [], []\n",
    "    n = len(imfs[-1])\n",
    "    flags = [0] * len(imfs)  # 0 = real\n",
    "\n",
    "    while len(imfs) < max_imf:\n",
    "        nueva = np.copy(imfs[-1])\n",
    "        if nueva.size != n:\n",
    "            nueva = np.resize(nueva, n)\n",
    "        imfs.append(nueva)\n",
    "        flags.append(1)      # 1 = sintética (duplicada)\n",
    "    return imfs, flags\n",
    "\n",
    "# ----------------- Recorrido solo para generar IMFs -----------------\n",
    "rows_imfs = []  # guardará sujeto/palabra/época/canal + imfs y flags (objetos)\n",
    "\n",
    "for suj in range(1, len(S) + 1):\n",
    "    sujeto = S[suj-1]\n",
    "    for pal_idx, palabra in enumerate(sujeto.Palabra, start=1):\n",
    "        pal_nombre = etiquetas_palabras[pal_idx-1]\n",
    "        n_ep = len(palabra.Epoca)\n",
    "        for ep in range(1, n_ep + 1):\n",
    "            X = palabra.Epoca[ep-1].SenalesEEG\n",
    "            if X.ndim != 2 or X.shape[1] < 14:\n",
    "                print(f\"[Aviso] S{suj} {pal_nombre} E{ep}: forma inesperada {X.shape}\")\n",
    "                continue\n",
    "            \n",
    "            eeg = X[:, :14]\n",
    "            \n",
    "            for ch in range(14):\n",
    "                canal_nombre = CANAL_EEG[ch]\n",
    "                sig = preproc_1d(eeg[:, ch])\n",
    "\n",
    "                imfs = compute_imfs_1d(sig, max_imf=MAX_IMF)\n",
    "                imfs, flags = completar_imfs(imfs, max_imf=MAX_IMF)\n",
    "\n",
    "                rows_imfs.append({\n",
    "                    \"sujeto\": suj,\n",
    "                    \"palabra\": pal_nombre,\n",
    "                    \"epoca\": ep,\n",
    "                    \"canal\": canal_nombre,\n",
    "                    \"imfs\": imfs,    # lista de np.array (MAX_IMF x n)\n",
    "                    \"flags\": flags   # lista de ints (0/1)\n",
    "                })\n",
    "                \n",
    "df_imfs = pd.DataFrame(rows_imfs)\n",
    "df_imfs.to_pickle(\"imfs_intermedio.pkl\")  # intermedio para la Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448382e",
   "metadata": {},
   "source": [
    "### Extracción de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features calculadas y guardadas en dataset.csv\n",
      " sujeto palabra  epoca canal  imf    Energia  Media_Energia  Varianza_Energia  Picos_energia  Entropia_Shannon  Skewness  Curtosis  Picos_max  Picos_min  Picos_totales  Envolvente_media  Envolvente_std  Freq_media  Freq_var  Freq_picos  Entropia_espectral  Ancho_banda  Centroide_espectral  IMF_sintetica\n",
      "      1  Arriba      1   AF3    1   0.425520       0.001891          0.000006             85          5.147605 -0.041231 -0.284698         54         54            108          0.055041        0.027438   30.450709 80.930531          38            3.518398     6.848998            31.590451              0\n",
      "      1  Arriba      1   AF3    2   0.411931       0.001831          0.000012             41          4.993844 -0.129535  1.693831         21         20             41          0.047603        0.037119   11.879821 52.728003          39            2.974037     4.833090             7.401295              0\n",
      "      1  Arriba      1   AF3    3   2.120080       0.009423          0.000305             14          4.891942 -0.682666  1.306576          7          7             14          0.104348        0.088922    3.935261  5.273063          86            2.022012     1.404057             2.427025              0\n",
      "      1  Arriba      1   AF3    4  15.309212       0.068041          0.016445              6          4.683060  0.967606  1.218208          3          3              6          0.280353        0.238031    0.992463  0.505913          78            1.491242     0.634900             1.043266              0\n",
      "      1  Arriba      1   AF3    5 156.738793       0.696617          0.583174              1          5.268489  0.939828 -0.710645          1          1              2          1.068528        0.501180    0.636420  0.229549          74            0.774067     0.298862             0.542283              0\n"
     ]
    }
   ],
   "source": [
    "# === PARTE 2: EXTRACCIÓN DE CARACTERÍSTICAS ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import hilbert, welch, find_peaks\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "\n",
    "FS = 128\n",
    "\n",
    "def compute_features(imf):\n",
    "    base_cols = [\n",
    "        \"Energia\",\"Media_Energia\",\"Varianza_Energia\",\n",
    "        \"Envolvente_media\",\"Envolvente_std\",\n",
    "        \"Freq_media\",\"Freq_var\",\"Freq_picos\",\n",
    "        \"Entropia_Shannon\",\"Skewness\",\"Curtosis\",\n",
    "        \"Entropia_espectral\",\"Ancho_banda\",\"Centroide_espectral\",\n",
    "        \"Picos_energia\",\"Picos_max\", \"Picos_min\", \"Picos_totales\"\n",
    "    ]\n",
    "\n",
    "    if imf is None or len(imf) == 0:\n",
    "        return {c: np.nan for c in base_cols}\n",
    "    \n",
    "    x = np.asarray(imf, dtype=float)\n",
    "    n = len(x)\n",
    "\n",
    "    #---Energia y demas estadisticas---#  \n",
    "\n",
    "    energia = np.sum(x**2) \n",
    "    media_energia = energia / n  \n",
    "    varianza_energia = np.var(x**2) \n",
    "    skewness = skew(x, bias=False) if n > 2 else np.nan \n",
    "    curt = kurtosis(x, bias=False) if n > 3 else np.nan \n",
    "\n",
    "    #---Entropía---#\n",
    "    suma_abs = np.sum(np.abs(x))\n",
    "    probs = (np.abs(x)/suma_abs) if suma_abs > 0 else None # Conversion a probabilidad discreta\n",
    "    shannon = entropy(probs) if probs is not None else np.nan\n",
    "\n",
    "    #---Picos de la IMF---#\n",
    "    picos_energia, _ = find_peaks(x**2) \n",
    "    picos_maximos, _ = find_peaks(x) \n",
    "    picos_minimos, _ = find_peaks(-x) \n",
    "    picos_totales = len(picos_maximos) + len(picos_minimos) \n",
    "\n",
    "    #---Hilbert---#\n",
    "    analytic = hilbert(x) \n",
    "    envolvente = np.abs(analytic) \n",
    "    envolvente_media = np.mean(envolvente) \n",
    "    envolvente_std = np.std(envolvente) \n",
    "\n",
    "    #---Frecuencia instantánea---#\n",
    "    inst_phase = np.unwrap(np.angle(analytic))\n",
    "    dphase = np.diff(inst_phase)\n",
    "    if dphase.size:\n",
    "            inst_freq = (dphase / (2.0 * np.pi)) * FS\n",
    "            # enmascara fuera de (0, FS/2)\n",
    "            valid = (inst_freq > 0) & (inst_freq < FS/2)\n",
    "            inst_freq = np.where(valid, inst_freq, np.nan)\n",
    "            freq_media = np.nanmean(inst_freq)\n",
    "            freq_var = np.nanvar(inst_freq)\n",
    "            # contar picos sólo en valores finitos\n",
    "            finite = np.isfinite(inst_freq)\n",
    "            freq_picos = find_peaks(inst_freq[finite])[0] if finite.any() else []\n",
    "            freq_n_picos = len(freq_picos)\n",
    "    else:\n",
    "            freq_media = np.nan\n",
    "            freq_var = np.nan\n",
    "            freq_n_picos = 0\n",
    "    \n",
    "    #---Densidad espectral, centroide \n",
    "    f, Pxx = welch(x, fs=FS, nperseg=min(256, n)) #estimar la densidad espectral de potencia\n",
    "    if Pxx.size > 0 and np.sum(Pxx) > 0:\n",
    "        Pxx = Pxx / np.sum(Pxx)\n",
    "        entropia_espectral = entropy(Pxx) \n",
    "        centroide = np.sum(f * Pxx) \n",
    "        ancho_banda = np.sqrt(np.sum(((f-centroide)**2)*Pxx)) \n",
    "    else:\n",
    "        entropia_espectral = np.nan\n",
    "        centroide = np.nan\n",
    "        ancho_banda = np.nan\n",
    "\n",
    "\n",
    "\n",
    "#--- Coherencia PAC y la otra jaja---#\n",
    "\n",
    "    return {\n",
    "        \"Energia\": energia,\n",
    "        \"Media_Energia\": media_energia,\n",
    "        \"Varianza_Energia\": varianza_energia,\n",
    "        \"Envolvente_media\": envolvente_media,\n",
    "        \"Envolvente_std\": envolvente_std,\n",
    "        \"Freq_media\": freq_media,\n",
    "        \"Freq_var\": freq_var,\n",
    "        \"Freq_picos\": freq_n_picos,\n",
    "        \"Entropia_Shannon\": shannon,\n",
    "        \"Skewness\": skewness,\n",
    "        \"Curtosis\": curt,\n",
    "        \"Entropia_espectral\": entropia_espectral,\n",
    "        \"Ancho_banda\": ancho_banda,\n",
    "        \"Centroide_espectral\": centroide,\n",
    "        \"Picos_energia\": len(picos_energia),\n",
    "        \"Picos_max\": len(picos_maximos),\n",
    "        \"Picos_min\": len(picos_minimos),\n",
    "        \"Picos_totales\": picos_totales\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for _, row in df_imfs.iterrows():\n",
    "    imfs = row[\"imfs\"]\n",
    "    flags = row[\"flags\"]\n",
    "    # assert fuerte para que no se trunque con zip\n",
    "    if len(imfs) != len(flags):\n",
    "        raise ValueError(f\"Largo imfs ({len(imfs)}) != flags ({len(flags)}) en {row.get('sujeto')}-{row.get('palabra')}-{row.get('epoca')}-{row.get('canal')}\")\n",
    "    for k, (imf, flag) in enumerate(zip(imfs, flags), start=1):\n",
    "        feats = compute_features(imf)\n",
    "        feats.update({\n",
    "            \"sujeto\": row[\"sujeto\"],\n",
    "            \"palabra\": row[\"palabra\"],\n",
    "            \"epoca\": row[\"epoca\"],\n",
    "            \"canal\": row[\"canal\"],\n",
    "            \"imf\": k,\n",
    "            \"IMF_sintetica\": flag\n",
    "        })\n",
    "        rows.append(feats)\n",
    "\n",
    "df_features = pd.DataFrame(rows)\n",
    "\n",
    "cols_ordenadas = [\n",
    "    \"sujeto\", \"palabra\", \"epoca\", \"canal\", \"imf\",\n",
    "    \"Energia\",\"Media_Energia\",\"Varianza_Energia\",\n",
    "    \"Picos_energia\",\"Entropia_Shannon\",\n",
    "    \"Skewness\",\"Curtosis\",\"Picos_max\",\"Picos_min\",\n",
    "    \"Picos_totales\", \"Envolvente_media\",\"Envolvente_std\",\n",
    "    \"Freq_media\",\"Freq_var\",\"Freq_picos\",\n",
    "    \"Entropia_espectral\",\"Ancho_banda\",\"Centroide_espectral\",\n",
    "    \"IMF_sintetica\"\n",
    "]\n",
    "df_features = df_features[cols_ordenadas]\n",
    "\n",
    "out_name = \"dataset.csv\"\n",
    "df_features.to_csv(out_name, index=False)\n",
    "print(f\"Features calculadas y guardadas en {out_name}\")\n",
    "print(df_features.head().to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
